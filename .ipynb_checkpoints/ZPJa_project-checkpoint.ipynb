{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e85fbc-725a-4ce2-96b3-ecfce144a575",
   "metadata": {},
   "source": [
    "# Import dependencies and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "721c1ece-becd-4874-8ef4-e5acafab13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "from json_repair import repair_json, loads\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "from mwzeval.metrics import Evaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import copy\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de500f73-397d-490f-9d16-808ebba458eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\") #substitute with your own access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06072fb9-ceec-4177-bc0f-db867f732f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aba964885004ff5a08e6073d58c48ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9479db76a2954ba698376d0c6ae1ebe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ed53cac95d4114aba20c7c6989cfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"pirxus/spokenwoz-whisper\")\n",
    "dataset = dataset.remove_columns(\"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fdf50c8-cd7b-4766-ad55-860b7b10b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 73950\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 9104\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 17652\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wav_id': 'MUL0003',\n",
       " 'turn_index': 10,\n",
       " 'text': 'I will go there on Friday.',\n",
       " 'agent_text': 'and most of the time do like to arrive there.',\n",
       " 'domains': \"['restaurant']\",\n",
       " 'slots': \"{'restaurant': {'day': 'Friday', 'people': '1', 'area': 'centre', 'food': 'Indian'}}\",\n",
       " 'context': {'turn_index': [0, 2, 4, 6, 8],\n",
       "  'text': ['Hello, is this Customer Service Center?',\n",
       "   \"Well, I'm looking for a place to dine. Do you have any recommendation for me?\",\n",
       "   \"Well, I'd like to stay in the place with convenient transportation.\",\n",
       "   \"I'd like to try some Indian food.\",\n",
       "   'Yes, please. Book a table for one people.'],\n",
       "  'agent_text': ['Yes, this is Cosmos Service Center. How may I help?',\n",
       "   'Of course, there are plenty of restaurants. Do you have any specific area?',\n",
       "   'Okay, do you have any specific food type?',\n",
       "   'Let me check it for you. Yes, we got you a panel located in the center of the city, could meet your requirement. Do you want to book table?',\n",
       "   'Okay, and what day would you like to have your meal?'],\n",
       "  'domains': ['[]',\n",
       "   '[]',\n",
       "   \"['restaurant']\",\n",
       "   \"['restaurant']\",\n",
       "   \"['restaurant']\"],\n",
       "  'slots': ['{}',\n",
       "   '{}',\n",
       "   \"{'restaurant': {'area': 'centre'}}\",\n",
       "   \"{'restaurant': {'area': 'centre', 'food': 'Indian'}}\",\n",
       "   \"{'restaurant': {'people': '1', 'area': 'centre', 'food': 'Indian'}}\"]}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset)\n",
    "dataset['train'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66b621-63ba-4c68-a011-eb06b463b1c0",
   "metadata": {},
   "source": [
    "# Sentence embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8cf28",
   "metadata": {},
   "source": [
    "Embedders are used to transform a string into a vector, so similar strings can be found by comparing (cosine similarity) the vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e90aa0dc-9086-4fe8-b9b5-8d7ddd01b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_d2f = SentenceTransformer('sergioburdisso/dialog2flow-joint-bert-base')\n",
    "embedder_labse = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5e74cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(sample, only_user=False, include_state=True):\n",
    "    dialogue = \"\"\n",
    "    for j in range(len(sample[\"context\"][\"text\"])):\n",
    "        if only_user:\n",
    "            dialogue += \" \" + sample[\"context\"][\"text\"][j]\n",
    "        else:\n",
    "            dialogue += \" User: \" + sample[\"context\"][\"text\"][j]\n",
    "            dialogue += \" Agent: \" + sample[\"context\"][\"agent_text\"][j]\n",
    "    if not only_user:\n",
    "        dialogue += \" User:\"\n",
    "    dialogue += \" \" + sample[\"text\"]\n",
    "    if include_state:\n",
    "        dialogue += \" Domains: \" + sample[\"domains\"]\n",
    "        dialogue += \" Slots: \" + sample[\"slots\"]\n",
    "    return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7019b047-b9ff-4cdf-825b-b83a843a232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading D2F embedded dataset...\n",
      "Reading file...\n",
      "Loading LaBSE embedded dataset...\n",
      "Reading file...\n"
     ]
    }
   ],
   "source": [
    "def embed_dataset(embedder, dataset, path, batch_size=1024):\n",
    "    #If the dataset was already embedded, load it from a file to save time\n",
    "    if os.path.exists(path):\n",
    "        print(\"Reading file...\")\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    print(\"Embedding rows...\")\n",
    "    embedded_rows = []\n",
    "    num_batches = (len(dataset) + batch_size - 1) // batch_size\n",
    "    for batch_idx, batch_start in enumerate(range(0, len(dataset), batch_size), start=1):\n",
    "        batch = dataset[batch_start:batch_start + batch_size]\n",
    "\n",
    "        embeddings = embedder.encode(\n",
    "            [extract_dialogue(sample) for sample in batch],\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "\n",
    "        for sample, embedding in zip(batch, embeddings):\n",
    "            embedded_rows.append({\n",
    "#                'wav_id': sample['wav_id'],\n",
    "#                'turn_index': sample['turn_index'],\n",
    "                'embedding': embedding\n",
    "            })\n",
    "\n",
    "        print(f\"Processed batch {batch_idx}/{num_batches} \"\n",
    "              f\"({min(batch_start + batch_size, len(dataset))}/{len(dataset)} samples)\")\n",
    "    print(\"Writing to file...\")\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(embedded_rows, f)\n",
    "    return embedded_rows \n",
    "\n",
    "dataset_list = list(dataset['train'])\n",
    "print(\"Loading D2F embedded dataset...\")\n",
    "embedded_train_d2f = embed_dataset(embedder_d2f, dataset_list, \"embedded_train.d2f\")\n",
    "print(\"Loading LaBSE embedded dataset...\")\n",
    "embedded_train_labse = embed_dataset(embedder_labse, dataset_list, \"embedded_train.labse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cda71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_most_similar(sample, k, embedder, dataset, embedded_dataset):\n",
    "    sample_emb = embedder.encode(extract_dialogue(sample))\n",
    "    \n",
    "    M = np.stack([row['embedding'] for row in embedded_dataset]).astype(np.float32)\n",
    "    s = np.array(sample_emb).astype(np.float32)\n",
    "    \n",
    "    M_norm = M / np.linalg.norm(M, axis=1, keepdims=True)\n",
    "    s_norm = s / np.linalg.norm(s)\n",
    "\n",
    "    sims = M_norm @ s_norm # cosine similarities\n",
    "    sims[sims >= 0.999999] = -np.inf\n",
    "\n",
    "    idx = np.argpartition(sims, -k)[-k:]\n",
    "    idx = idx[np.argsort(sims[idx])[::-1]]\n",
    "\n",
    "    samples   = [dataset[i] for i in idx]\n",
    "    scores = sims[idx].tolist()\n",
    "    return samples, scores\n",
    "\n",
    "def random_k_demonstrations(k, dataset):\n",
    "    return [dataset[p] for p in random.sample(range(len(dataset)), k)]\n",
    "\n",
    "#find_k_most_similar(dataset['test'][140], 10, embedder_d2f, dataset['train'], embedded_train_d2f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745661b",
   "metadata": {},
   "source": [
    "# Prompt creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db4f75e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sample, k, embedder_name, only_user=False):\n",
    "    if k > 0:\n",
    "        assert(embedder_name == \"D2F\" or embedder_name == \"LaBSE\" or embedder_name == \"random\")\n",
    "        if embedder_name == \"D2F\":\n",
    "            (demonstrations, _) = find_k_most_similar(sample, k, embedder_d2f, dataset['train'], embedded_train_d2f)\n",
    "        elif embedder_name == \"LaBSE\":\n",
    "            (demonstrations, _) = find_k_most_similar(sample, k, embedder_labse, dataset['train'], embedded_train_labse)\n",
    "        else:\n",
    "            demonstrations = random_k_demonstrations(k, dataset['train'])\n",
    "        \n",
    "    #(demonstrations, _) = find_k_most_similar(sample, k, embedder, dataset['train'], embedded_dataset)\n",
    "    prompt = 'Instruction: Identify the slot keys and values.\\n'\n",
    "    for i in range(k):\n",
    "        prompt += extract_dialogue(demonstrations[k-i-1], only_user, include_state=True) + \"\\n\"\n",
    "    #New sample\n",
    "    prompt += extract_dialogue(sample, only_user, include_state=False)\n",
    "    prompt += \" Domains: \" + sample[\"domains\"]\n",
    "    prompt += \" Slots: \"\n",
    "    return prompt\n",
    "    \n",
    "#create_prompt(dataset['train'][130], 1, \"random\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d0aea-dff5-4f15-9b5f-62993549c130",
   "metadata": {},
   "source": [
    "# LLM and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b92359c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4798c5ecb44d1eb8abb04828975f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2385eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Identify the slot keys and values.\n",
      " User: Hi, is this customer service? Agent: Yes, anything I can help you. User: I'm looking for a guest house in the north of Cambridge. Domains: ['attraction'] Slots: {'attraction': {'area': 'North'}}\n",
      " User: Hi, is it customer service? Agent: Yes, anything I can help you. User: I'm looking for a guest house in the south of Cambridge. Domains: ['hotel'] Slots: \n"
     ]
    }
   ],
   "source": [
    "sample = dataset['test'][230]\n",
    "prompt = create_prompt(sample, 1, \"D2F\", False)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8783a8",
   "metadata": {},
   "source": [
    "To repair the model's answer we load it with json-repair to get rid of extra text, and in case there are multiple dictionaries only take the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f9c7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_output(output):\n",
    "    try:\n",
    "        obj = loads(output)\n",
    "        if type(obj) is list:\n",
    "            obj = obj[0] if obj else {}\n",
    "        return obj\n",
    "    except Exception as e:\n",
    "        print(\"Exception during json repair: \", e)\n",
    "        return \"\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9f56666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'hotel': {'area': 'South'}}\n",
      " User: Hi, is it customer service? Agent: Yes, anything I can help you. User: I'm looking for a guest house in the south of Cambridge. Domains: ['hotel'] Slots: {'hotel': {'area': 'South'}}\n",
      " Agent: I can help you with that. Can you please tell me the area where you are looking for a guest house? User: I'm looking for a guest house in the south of Cambridge. Domains: ['area'] Slots: {'area': 'South'}\n",
      " Agent: I can help you\n",
      "Repaired output:  {'hotel': {'area': 'South'}}\n",
      "Ground truth:  {'hotel': {'area': 'South', 'type': 'guest house'}}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=120, pad_token_id=tokenizer.eos_token_id)\n",
    "output_string = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])\n",
    "output_repaired = repair_output(output_string)\n",
    "print(output_string)\n",
    "print(\"Repaired output: \", output_repaired)\n",
    "print(\"Ground truth: \", sample[\"slots\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6155e4e",
   "metadata": {},
   "source": [
    "# Metrics and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca860020",
   "metadata": {},
   "source": [
    "Here we create the dictionary used as input for the evaluation function: we put all dialogues as separate key-values, where the value is a dict containing a single turn.<br>\n",
    "When creating the turn dictionary, we remove badly generated data (which, for example, don't have nested dicts for slots, or which are not dicts at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6d31c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception for sample  MUL0062  turn  2  with output  {\n",
      "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    }
   ],
   "source": [
    "output_test_1 = '{\"hotel\": {\"area\": \"East\", \"price\": \"expensive\", \"number_of_people\": \"four\", \"stay_duration\": \"more than four nights\", \"start_date\": \"third day of week\", \"rating\": \"four-star\"}, \"profile\": {\"name\": \"Josephina Coffey\", \"email\": \"None\"}, \"restaurant\": {\"area\": \"East\", \"price\": \"expensive\"}}'\n",
    "output_test_2 = '{\"hotel\": {\"day\": \"Friday\", \"people\": \"4\", \"stay\": \"5\", \"area\": \"South\", \"parking\": \"yes\", \"pricerange\": \"moderate\", \"stars\": \"4\", \"type\": \"guest house\"}, \"profile\": {\"name\": \"Josefina Coffey\", \"platenumber\": \"xw54nvh\"}, \"restaurant\": {\"name\": \"Mahal Of Cambridge\"}}'\n",
    "\n",
    "def remove_bad_data(dictionary):\n",
    "    to_remove = []\n",
    "    to_remove_inner = []\n",
    "    for k, v in dictionary.items():\n",
    "        #print(v)\n",
    "        if not type(v) is dict:\n",
    "            to_remove.append(k)\n",
    "        else:\n",
    "            for k1, v1 in v.items():\n",
    "                if not type(v1) is str and not type(v1) is int:\n",
    "                    to_remove_inner.append([k, k1])\n",
    "    for k in to_remove:\n",
    "        del dictionary[k]\n",
    "    for ks in to_remove_inner:\n",
    "        del dictionary[ks[0]][ks[1]]\n",
    "    return dictionary\n",
    "\n",
    "def prepare_evaluation_entry(gt_sample, generated_json):\n",
    "    slots_dict = json.loads(generated_json) if type(generated_json) is str else copy.deepcopy(generated_json)\n",
    "    slots_dict = remove_bad_data(slots_dict)\n",
    "    domains_list = ast.literal_eval(gt_sample[\"domains\"])\n",
    "    turn_dict = {\"response\": \"\", \"turn_index\": int(gt_sample[\"turn_index\"]/2), \"state\": slots_dict, \"active_domains\": domains_list}\n",
    "    return gt_sample[\"wav_id\"], turn_dict\n",
    "\n",
    "def prepare_empty_entry(gt_sample):\n",
    "    slots_dict = {}\n",
    "    domains_list = ast.literal_eval(gt_sample[\"domains\"])\n",
    "    turn_dict = {\"response\": \"\", \"turn_index\": int(gt_sample[\"turn_index\"]/2), \"state\": slots_dict, \"active_domains\": domains_list}\n",
    "    return gt_sample[\"wav_id\"], turn_dict\n",
    "\n",
    "def prepare_evaluation_dict(gt_samples, generated_jsons):\n",
    "    out_dict = {}\n",
    "    for i in range(len(gt_samples)):\n",
    "        try:\n",
    "            key, value = prepare_evaluation_entry(gt_samples[i], generated_jsons[i])\n",
    "            out_dict.setdefault(key, []).append(value)\n",
    "        except Exception as e:\n",
    "            print(\"Exception for sample \", gt_samples[i][\"wav_id\"], \" turn \", gt_samples[i][\"turn_index\"], \" with output \", generated_jsons[i])\n",
    "            print(e)\n",
    "            key, value = prepare_empty_entry(gt_samples[i])\n",
    "            out_dict.setdefault(key, []).append(value)\n",
    "    return out_dict\n",
    "\n",
    "evaluation_dict = prepare_evaluation_dict([sample, sample, sample], [output_test_1, output_test_2, \"{\"])\n",
    "#print(evaluation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96afa29a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing ground truth data\n",
      "Normalizing predictions data ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_accuracy': 0.0, 'slot_error_rate': 366.66666666666663, 'slot_total_ref': 6, 'slot_total_hyp': 21, 'slot_f1': 22.222222218600823, 'slot_precision': 14.28571428564626, 'slot_recall': 49.99999999916667}\n"
     ]
    }
   ],
   "source": [
    "e = Evaluator(bleu=False, success=False, richness=False, dst=True)\n",
    "results = e.evaluate(evaluation_dict)\n",
    "print(results['dst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b86070e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_tokens(sample):\n",
    "    tokens = tokenizer.encode(sample[\"slots\"])\n",
    "    return len(tokens) + 20\n",
    "\n",
    "def get_stored_lines(path):\n",
    "    if path is None:\n",
    "        return []\n",
    "    if not os.path.exists(path):\n",
    "        open(path, \"w\").close()\n",
    "        return []\n",
    "    arr = []\n",
    "    with open(path, \"r\") as f:\n",
    "        arr = f.readlines()\n",
    "    return arr\n",
    "\n",
    "def init_results_from_test_type(test_type):\n",
    "    if test_type == \"demonstrations\":\n",
    "        return [[] for k in [1, 3, 5, 10]]\n",
    "    else:\n",
    "        return [[], []]\n",
    "\n",
    "def get_prompts_from_test_type(sample, test_type):\n",
    "    if test_type == \"utterances\":\n",
    "        return [create_prompt(sample, k=3, embedder_name=\"D2F\", only_user=u) for u in [True, False]]\n",
    "    elif test_type == \"demonstrations\":\n",
    "        return [create_prompt(sample, k, embedder_name=\"D2F\", only_user=True) for k in [0, 1, 3, 5]]\n",
    "    elif test_type == \"embedder\":\n",
    "        return [create_prompt(sample, k=3, embedder_name=emb, only_user=True) for emb in [\"random\", \"D2F\", \"LaBSE\"]]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def test_model(samples, device, test_type, path = None):\n",
    "    results = init_results_from_test_type(test_type)\n",
    "    num_lines = 0\n",
    "    if path is not None:\n",
    "        file_lines = get_stored_lines(path)\n",
    "        num_lines = len(file_lines) \n",
    "    c = 0\n",
    "    for sample in tqdm.tqdm(samples, desc=\"Processing samples\", position = 0):\n",
    "        prompts = get_prompts_from_test_type(sample, test_type)\n",
    "        max_tokens = get_max_tokens(sample)\n",
    "        for i in range(len(prompts)):\n",
    "            if c < num_lines:\n",
    "                result = json.loads(file_lines[c])\n",
    "            else:\n",
    "                inputs = tokenizer(prompts[i], return_tensors=\"pt\").to(model.device)\n",
    "                outputs = model.generate(**inputs, max_new_tokens=max_tokens, pad_token_id=tokenizer.eos_token_id)\n",
    "                result = repair_output(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
    "                if not path is None and os.path.exists(path):\n",
    "                    with open(path, \"a\") as f:\n",
    "                        print(json.dumps(result), file = f)\n",
    "            results[i].append(result)\n",
    "            c = c+1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6ccbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing ground truth data\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "e = Evaluator(bleu=False, success=False, richness=False, dst=True)\n",
    "n = 100\n",
    "all_positions = list(range(len(dataset['test'])))\n",
    "random.shuffle(all_positions)\n",
    "\n",
    "positions = all_positions[:n]\n",
    "\n",
    "samples = [dataset['test'][p] for p in positions]\n",
    "    \n",
    "def eval_model_outputs(samples, outputs):\n",
    "    print(\"Evaluating model...\")\n",
    "    eval_dicts = [prepare_evaluation_dict(samples, res) for res in outputs]\n",
    "    eval_results = [e.evaluate(eval_dict)['dst'] for eval_dict in eval_dicts]\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6b5f42e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:  26%|██████████████▌                                         | 26/100 [1:26:16<4:05:33, 199.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m outputs_utterances = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutterances\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutterance_outputs.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m metrics_utterances = eval_model_outputs(samples, outputs_utterances)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m(samples, device, test_type, path)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     46\u001b[39m     inputs = tokenizer(prompts[i], return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     result = repair_output(tokenizer.decode(outputs[\u001b[32m0\u001b[39m][inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]:]))\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os.path.exists(path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\generation\\utils.py:2787\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2789\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2790\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2791\u001b[39m     outputs,\n\u001b[32m   2792\u001b[39m     model_kwargs,\n\u001b[32m   2793\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2794\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:459\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    441\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:395\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    407\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    408\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    409\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:292\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    281\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    289\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    290\u001b[39m ) -> torch.Tensor:\n\u001b[32m    291\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m    294\u001b[39m     hidden_states, _ = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    295\u001b[39m         hidden_states=hidden_states,\n\u001b[32m    296\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m         **kwargs,\n\u001b[32m    303\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Programmi\\miniconda3\\envs\\zpja2\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:65\u001b[39m, in \u001b[36mLlamaRMSNorm.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m     63\u001b[39m input_dtype = hidden_states.dtype\n\u001b[32m     64\u001b[39m hidden_states = hidden_states.to(torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m variance = \u001b[43mhidden_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m.mean(-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     66\u001b[39m hidden_states = hidden_states * torch.rsqrt(variance + \u001b[38;5;28mself\u001b[39m.variance_epsilon)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight * hidden_states.to(input_dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "outputs_utterances = test_model(samples, device=device, test_type=\"utterances\", path=\"utterance_outputs.txt\")\n",
    "metrics_utterances = eval_model_outputs(samples, outputs_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs_demonstrations = test_model(samples, device=device, test_type=\"demonstrations\", path=\"demonstration_outputs.txt\")\n",
    "#metrics_demonstrations = eval_model_outputs(samples, outputs_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs_embedder = test_model(samples, device=device, test_type=\"embedder\", path=\"embedder_outputs.txt\")\n",
    "#metrics_embedder = eval_model_outputs(samples, outputs_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metrics, labels):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
    "    axes = axes.flatten()\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"]\n",
    "    ser_height = max(max([m[\"slot_error_rate\"] for m in metrics]), 80) + 10\n",
    "    titles = [\"Joint accuracy\", \"Slot error rate\", \"Precision\", \"Recall\", \"F1\"]\n",
    "    metric_names = [\"joint_accuracy\", \"slot_error_rate\", \"slot_precision\", \"slot_recall\", \"slot_f1\"]\n",
    "    for i in range(5):\n",
    "        axes[i].bar(labels, [m[metric_names[i]] for m in metrics], label=labels, color=colors[:len(metrics)])\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].set_ylim(0, 100 if i != 1 else ser_height)\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd4d57fd-87b5-4a14-8cc7-a153f1e84530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterances results: \n",
      "[{'joint_accuracy': 15.999999999967999, 'slot_error_rate': 120.44609665427511, 'slot_total_ref': 269, 'slot_total_hyp': 263, 'slot_f1': 47.36842104761441, 'slot_precision': 47.90874524713008, 'slot_recall': 46.840148698867345}, {'joint_accuracy': 13.999999999972, 'slot_error_rate': 118.58736059479553, 'slot_total_ref': 269, 'slot_total_hyp': 263, 'slot_f1': 47.36842104761441, 'slot_precision': 47.90874524713008, 'slot_recall': 46.840148698867345}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x900 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Utterances results: \")\n",
    "print(metrics_utterances)\n",
    "\n",
    "plot_results(metrics_utterances, [\"Only user\", \"User and agent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demonstrations results: \")\n",
    "print(metrics_demonstrations)\n",
    "\n",
    "plot_results(metrics_demonstrations, [\"0 demonstrations\", \"1 demonstration\", \"3 demonstrations\", \"5 demonstrations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ca7ad-c7cb-4051-ae44-459798dad2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedder results: \")\n",
    "print(metrics_embedder)\n",
    "\n",
    "plot_results(metrics_embedder, [\"Random\", \"D2F\", \"LaBSE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zpja2",
   "language": "python",
   "name": "zpja2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
