{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e85fbc-725a-4ce2-96b3-ecfce144a575",
   "metadata": {},
   "source": [
    "# Install dependencies and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721c1ece-becd-4874-8ef4-e5acafab13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from hf_olmo import OLMoForCausalLM, OLMoTokenizerFast\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de500f73-397d-490f-9d16-808ebba458eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06072fb9-ceec-4177-bc0f-db867f732f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95caf7260cda41e7944ce19ffe4aa8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e86ea5a109b44e2a627ea826d008776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6c3268f4e94287948f3213f7b2e775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"pirxus/spokenwoz-whisper\")\n",
    "dataset = dataset.remove_columns(\"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdf50c8-cd7b-4766-ad55-860b7b10b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 73950\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 9104\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['wav_id', 'turn_index', 'text', 'agent_text', 'domains', 'slots', 'context'],\n",
      "        num_rows: 17652\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wav_id': 'MUL0003',\n",
       " 'turn_index': 10,\n",
       " 'text': 'I will go there on Friday.',\n",
       " 'agent_text': 'and most of the time do like to arrive there.',\n",
       " 'domains': \"['restaurant']\",\n",
       " 'slots': \"{'restaurant': {'day': 'Friday', 'people': '1', 'area': 'centre', 'food': 'Indian'}}\",\n",
       " 'context': {'turn_index': [0, 2, 4, 6, 8],\n",
       "  'text': ['Hello, is this Customer Service Center?',\n",
       "   \"Well, I'm looking for a place to dine. Do you have any recommendation for me?\",\n",
       "   \"Well, I'd like to stay in the place with convenient transportation.\",\n",
       "   \"I'd like to try some Indian food.\",\n",
       "   'Yes, please. Book a table for one people.'],\n",
       "  'agent_text': ['Yes, this is Cosmos Service Center. How may I help?',\n",
       "   'Of course, there are plenty of restaurants. Do you have any specific area?',\n",
       "   'Okay, do you have any specific food type?',\n",
       "   'Let me check it for you. Yes, we got you a panel located in the center of the city, could meet your requirement. Do you want to book table?',\n",
       "   'Okay, and what day would you like to have your meal?'],\n",
       "  'domains': ['[]',\n",
       "   '[]',\n",
       "   \"['restaurant']\",\n",
       "   \"['restaurant']\",\n",
       "   \"['restaurant']\"],\n",
       "  'slots': ['{}',\n",
       "   '{}',\n",
       "   \"{'restaurant': {'area': 'centre'}}\",\n",
       "   \"{'restaurant': {'area': 'centre', 'food': 'Indian'}}\",\n",
       "   \"{'restaurant': {'people': '1', 'area': 'centre', 'food': 'Indian'}}\"]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset)\n",
    "dataset['train'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66b621-63ba-4c68-a011-eb06b463b1c0",
   "metadata": {},
   "source": [
    "# Sentence embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90aa0dc-9086-4fe8-b9b5-8d7ddd01b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('sergioburdisso/dialog2flow-joint-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e74cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(sample, only_user=False, include_state=True):\n",
    "    dialogue = \"\"\n",
    "    for j in range(len(sample[\"context\"][\"text\"])):\n",
    "        if only_user:\n",
    "            dialogue += \" \" + sample[\"context\"][\"text\"][j]\n",
    "        else:\n",
    "            dialogue += \" User: \" + sample[\"context\"][\"text\"][j]\n",
    "            dialogue += \" Agent: \" + sample[\"context\"][\"agent_text\"][j]\n",
    "    if not only_user:\n",
    "        dialogue += \" User:\"\n",
    "    dialogue += \" \" + sample[\"text\"]\n",
    "    if include_state:\n",
    "        dialogue += \" Domains: \" + sample[\"domains\"]\n",
    "        dialogue += \" Slots: \" + sample[\"slots\"]\n",
    "    return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7019b047-b9ff-4cdf-825b-b83a843a232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_dataset(embedder, dataset, path, batch_size=128):\n",
    "    #If the dataset was already embedded, load it from a file to save time\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    embedded_rows = [\n",
    "    {\n",
    "        'wav_id': sample['wav_id'],\n",
    "        'turn_index': sample['turn_index'],\n",
    "        'embedding': embedding\n",
    "    }\n",
    "    for batch_start in range(0, len(dataset), batch_size)\n",
    "    for sample, embedding in zip(\n",
    "        dataset[batch_start:batch_start+batch_size],\n",
    "        embedder.encode(\n",
    "            [extract_dialogue(sample) for sample in dataset[batch_start:batch_start+batch_size]],\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "    )]\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(embedded_rows, f)\n",
    "    return embedded_rows \n",
    "\n",
    "embedded_train = embed_dataset(embedder, list(dataset['train'])[:512], \"embedded_train.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ba9bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_k_most_similar(sample, k, embedder, dataset, embedded_dataset):\n",
    "    sample_emb = embedder.encode(extract_dialogue(sample))\n",
    "    \n",
    "    M = np.stack([row['embedding'] for row in embedded_dataset])\n",
    "    s = np.array(sample_emb)\n",
    "    \n",
    "    dists = np.linalg.norm(M - s, axis=1) # L2 distance\n",
    "    dists[dists == 0] = np.inf # Ignore exact match\n",
    "\n",
    "    idx = np.argpartition(dists, k)[:k]\n",
    "    idx = idx[np.argsort(dists[idx])]\n",
    "\n",
    "    samples   = [dataset[i] for i in idx]\n",
    "    distances = dists[idx].tolist()\n",
    "    return samples, distances\n",
    "\n",
    "#find_k_most_similar(dataset['train'][120], 8, embedder, dataset['train'], embedded_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745661b",
   "metadata": {},
   "source": [
    "# Prompt creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db4f75e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sample, k, only_user=False):\n",
    "    (demonstrations, _) = find_k_most_similar(sample, k, embedder, dataset['train'], embedded_train)\n",
    "    prompt = 'Instruction: Identify the slot keys and values.\\n'\n",
    "    for i in range(k):\n",
    "        prompt += extract_dialogue(demonstrations[i], only_user, include_state=True) + \"\\n\"\n",
    "    #New sample\n",
    "    prompt += extract_dialogue(sample, only_user, include_state=False)\n",
    "    prompt += \" Domains: \" + sample[\"domains\"]\n",
    "    prompt += \" Slots: \"\n",
    "    return prompt\n",
    "    \n",
    "#create_prompt(dataset['train'][120], 3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d0aea-dff5-4f15-9b5f-62993549c130",
   "metadata": {},
   "source": [
    "# LLM and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b92359c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6870d358371548699f0b0e1bef824680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c973c8e9c614bca8f7ec23e611474e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc34ce0baa4a55a09de28cf7c9b2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b262234dc0e4c97afce596f210f7c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c52386b47ce494d95d0f109481f81d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:01<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2385eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Identify the slot keys and values.\n",
      " Hi. Hi, I need to stay overnight in Cambridge. Please find me a hotel. I'd like to find an expensive one. Domains: ['hotel'] Slots: {'hotel': {'pricerange': 'expensive', 'type': 'hotel'}}\n",
      " Hello? Yes, I'm looking for the information in Cambridge. I'm looking for a restaurant. I suppose the restaurant should be in the expensive price range. I will travel in the eastern part of the city, so I prefer to eat there. That's right. Do you have any recommendation of the restaurant? Okay. Okay, Mano. Okay, I suppose I would like to try the second one. No, but I need some other information. My know their post code Go ahead. Thank you so much. May I know the address? God, Ed, thank you very much. Also, I'm looking for a place to stay. Well, I suppose the hotel should be in the type of guest house. Domains: ['hotel', 'restaurant'] Slots: {'hotel': {'type': 'guest house'}, 'restaurant': {'area': 'East', 'name': 'Royal Standard'}}\n",
      " Hello? Yes, I'm looking for the information in Cambridge. I'm looking for a restaurant. I suppose the restaurant should be in the expensive price range. I will travel in the eastern part of the city, so I prefer to eat there. That's right. Do you have any recommendation of the restaurant? Okay. Okay, Mano. Okay, I suppose I would like to try the second one. No, but I need some other information. My know their post code Go ahead. Thank you so much. May I know the address? God, Ed, thank you very much. Also, I'm looking for a place to stay. Well, I suppose the hotel should be in the type of guest house. And I suppose we should be in the same area of the restaurant. Also, I suppose it should have a style of floor. Domains: ['hotel', 'restaurant'] Slots: {'hotel': {'area': 'East', 'stars': '4', 'type': 'guest house'}, 'restaurant': {'area': 'East', 'name': 'Royal Standard'}}\n",
      " Hi. Hi, I need to stay overnight in Cambridge. Please find me a hotel. I'd like to find an expensive one. And I need free internet and parking lots, please. Domains: ['hotel'] Slots: \n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'][100]\n",
    "prompt = create_prompt(sample, 3, True)\n",
    "print(prompt)\n",
    "messages = [\n",
    "    #{\"role\": \"system\", \"content\": \"Generate slot keys and values.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f56666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'hotel': {'pricerange': 'expensive', 'type': 'hotel', 'internet': 'free', 'parking': 'lots'}}\n",
      " Hello? Yes, I'm looking for the\n",
      "Ground truth:  {'hotel': {'internet': 'yes', 'parking': 'yes', 'pricerange': 'expensive', 'type': 'hotel'}}\n"
     ]
    }
   ],
   "source": [
    "#inputs = tokenizer.apply_chat_template(\n",
    "#    messages,\n",
    "#    add_generation_prompt=True,\n",
    "#    tokenize=True,\n",
    "#    return_dict=True,\n",
    "#    return_tensors=\"pt\",\n",
    "#).to(model.device)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
    "print(\"Ground truth: \", sample[\"slots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e19447-8dc3-4f6b-8e54-2d3d09e2d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zpja2",
   "language": "python",
   "name": "zpja2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
